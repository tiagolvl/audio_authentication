{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOflHFxOvQp+t440G89UAhr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# CONFIG"],"metadata":{"id":"x6GSiOcpWGOU"}},{"cell_type":"code","source":["!pip install soundfile optuna tqdm pyloudnorm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8KO13wuLiNS","executionInfo":{"status":"ok","timestamp":1764943889233,"user_tz":180,"elapsed":4432,"user":{"displayName":"Tiago Luz","userId":"17328043178737961243"}},"outputId":"26de2d68-1741-4d7d-823a-327ba2076cc2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Collecting pyloudnorm\n","  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.2)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pyloudnorm) (1.16.3)\n","Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from pyloudnorm) (1.0.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n","Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n","Installing collected packages: pyloudnorm\n","Successfully installed pyloudnorm-0.1.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_H4jHR4LkiT","executionInfo":{"status":"ok","timestamp":1764943855786,"user_tz":180,"elapsed":28208,"user":{"displayName":"Tiago Luz","userId":"17328043178737961243"}},"outputId":"5d5ac451-2dab-4ffc-a1bf-b91899adeabc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"id":"a-1xDPExKe_G","executionInfo":{"status":"ok","timestamp":1764955050623,"user_tz":180,"elapsed":3,"user":{"displayName":"Tiago Luz","userId":"17328043178737961243"}}},"outputs":[],"source":["import os\n","import torch\n","\n","# --- Paths ---\n","# In Colab, we extract to the local VM disk (/content/data) for speed\n","BASE_DATA_DIR = \"/content/data\"\n","RAW_DIR = os.path.join(BASE_DATA_DIR, \"01_raw\")\n","INTERMEDIARY_DIR = os.path.join(BASE_DATA_DIR, \"02_intermediary\")\n","MODEL_DIR = \"/content/drive/MyDrive/UFSC/topicos_especiais_aplicacoes/data/04_model\" # Save models directly to Drive so you don't lose them\n","EVALUATION_DIR = \"/content/drive/MyDrive/UFSC/topicos_especiais_aplicacoes/data/05_evaluation\"\n","\n","# Zip file configuration (Your Drive Path)\n","ZIP_FILENAME = \"LA.zip\"\n","# This points to the file in your Google Drive\n","ZIP_PATH = \"/content/drive/MyDrive/UFSC/topicos_especiais_aplicacoes/data/DS_10283_3336/LA.zip\"\n","\n","# The resulting root directory after unzipping\n","# Based on ASVspoof structure\n","DATASET_ROOT = os.path.join(RAW_DIR, \"LA\")\n","\n","# --- Protocol Paths ---\n","PATHS = {\n","    \"train\": {\n","        \"audio\": os.path.join(DATASET_ROOT, \"ASVspoof2019_LA_train/flac\"),\n","        \"protocol\": os.path.join(DATASET_ROOT, \"ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\")\n","    },\n","    \"dev\": {\n","        \"audio\": os.path.join(DATASET_ROOT, \"ASVspoof2019_LA_dev/flac\"),\n","        \"protocol\": os.path.join(DATASET_ROOT, \"ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\")\n","    },\n","    \"eval\": {\n","        \"audio\": os.path.join(DATASET_ROOT, \"ASVspoof2019_LA_eval/flac\"),\n","        \"protocol\": os.path.join(DATASET_ROOT, \"ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\")\n","    }\n","}\n","\n","# --- Audio Parameters ---\n","SAMPLE_RATE = 16000\n","DURATION = 4\n","SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n","LABEL_MAP = {\"bonafide\": 0, \"spoof\": 1}\n","\n","# --- Training Hyperparameters ---\n","# Colab T4 GPUs have 16GB VRAM, so we can increase batch size slightly\n","BATCH_SIZE = 128\n","GRAD_ACCUM_STEPS = 2 # Effective batch size = 32\n","EVAL_BATCH_SIZE = 256 # Increased for speed\n","\n","EPOCHS = 5 # Increased to allow convergence\n","N_TRIALS = 3 # Keep low for optimization speed\n","\n","FINAL_TRAINING_EPOCHS = 50\n","PATIENCE = 10\n","\n","# --- GPU Configuration ---\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# --- Data Subsetting ---\n","SAMPLES_PER_EPOCH = None\n","EVAL_SAMPLES = None"]},{"cell_type":"markdown","source":["# DATASET"],"metadata":{"id":"etuh8G7TVilq"}},{"cell_type":"code","source":["import os\n","import torch\n","import soundfile as sf\n","import numpy as np\n","import librosa\n","import pyloudnorm as pyln\n","import warnings\n","\n","from torch.utils.data import Dataset\n","\n","# Suppress warnings for cleaner logs\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","class ASVspoofDataset(Dataset):\n","    def __init__(self, df, target_length=64000, cache=True):\n","        self.df = df\n","        self.target_length = target_length\n","        self.cache = cache\n","\n","        # Pre-convert labels to tensor\n","        self.labels = torch.tensor(df['label'].values, dtype=torch.long)\n","        self.filenames = df['filename'].values\n","        self.subsets = df['subset'].values\n","\n","        # Setup Cache Directory\n","        self.cache_dir = os.path.join(INTERMEDIARY_DIR, \"processed_cache\")\n","        if self.cache:\n","            os.makedirs(self.cache_dir, exist_ok=True)\n","            print(f\"Dataset Cache enabled at: {self.cache_dir}\")\n","\n","        # --- LOAD SILERO VAD (Stage 1) ---\n","        try:\n","            # We only need to load VAD if we are actually processing data (not just reading cache)\n","            # But since we might encounter a missing cache file, we load it anyway.\n","            print(\"Loading Silero VAD for robust silence removal...\")\n","            self.vad_model, utils = torch.hub.load(\n","                repo_or_dir='snakers4/silero-vad',\n","                model='silero_vad',\n","                force_reload=False,\n","                trust_repo=True\n","            )\n","            (self.get_speech_timestamps, _, _, _, _) = utils\n","            self.vad_enabled = True\n","        except Exception as e:\n","            print(f\"Warning: Failed to load Silero VAD ({e}). Fallback to Librosa trim.\")\n","            self.vad_enabled = False\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _apply_mu_law(self, x, mu=255):\n","        \"\"\" Stage 3: Mu-Law Companding \"\"\"\n","        x_tensor = torch.as_tensor(x, dtype=torch.float32)\n","        numerator = torch.sign(x_tensor) * torch.log1p(mu * torch.abs(x_tensor))\n","        denominator = np.log1p(mu).astype(np.float32)\n","        return numerator / denominator\n","\n","    def _standardize_loudness(self, audio, sr):\n","        \"\"\" Stage 2: EBU R128 Normalization \"\"\"\n","        try:\n","            meter = pyln.Meter(sr)\n","            loudness = meter.integrated_loudness(audio)\n","            if not np.isinf(loudness):\n","                audio = pyln.normalize.loudness(audio, loudness, -23.0)\n","        except Exception:\n","            pass\n","        return audio.astype(np.float32)\n","\n","    def _process_temporal_structure(self, audio, sr):\n","        \"\"\" Stage 1: VAD and Audio Folding \"\"\"\n","        if self.vad_enabled and len(audio) > 512:\n","            try:\n","                wav_tensor = torch.from_numpy(audio).float()\n","                timestamps = self.get_speech_timestamps(wav_tensor, self.vad_model, sampling_rate=sr)\n","                if len(timestamps) > 0:\n","                    speech_chunks = [audio[ts['start']:ts['end']] for ts in timestamps]\n","                    audio = np.concatenate(speech_chunks)\n","            except Exception:\n","                pass\n","\n","        # Folding / Looping\n","        if len(audio) < self.target_length:\n","            repeat_count = (self.target_length // len(audio)) + 1\n","            audio = np.tile(audio, repeat_count)\n","\n","        # Cropping\n","        if len(audio) > self.target_length:\n","            start = np.random.randint(0, len(audio) - self.target_length)\n","            audio = audio[start : start + self.target_length]\n","\n","        return audio.astype(np.float32)\n","\n","    def extract_robust_features(self, y, sr):\n","        \"\"\" Stage 4: Advanced Bio-Physical Features \"\"\"\n","        epsilon = 1e-10\n","\n","        # Feature 1: TEO\n","        teo = y[1:-1]**2 - y[:-2] * y[2:]\n","        teo_log = np.log(np.abs(teo) + epsilon)\n","        teo_mean = np.mean(teo_log)\n","\n","        # Feature 2: PCEN Flux\n","        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64, fmax=8000)\n","        S_pcen = librosa.pcen(S * (2**31))\n","        flux = librosa.onset.onset_strength(S=S_pcen, sr=sr)\n","        pcen_flux_mean = np.mean(flux)\n","\n","        # Feature 3: Unvoiced Length Proxy\n","        zcr = librosa.feature.zero_crossing_rate(y=y)[0]\n","        rms = librosa.feature.rms(y=y)[0]\n","        rms_norm = (rms - np.min(rms)) / (np.max(rms) - np.min(rms) + epsilon)\n","\n","        unvoiced_mask = (zcr > 0.1) & (rms_norm < 0.2)\n","        padded = np.pad(unvoiced_mask, (1, 1), 'constant')\n","        diff = np.diff(padded.astype(int))\n","        lengths = np.where(diff == -1)[0] - np.where(diff == 1)[0]\n","        unvoiced_len = np.mean(lengths) if len(lengths) > 0 else 0.0\n","\n","        features = np.array([teo_mean, pcen_flux_mean, unvoiced_len], dtype=np.float32)\n","        features = (features - np.mean(features)) / (np.std(features) + epsilon)\n","        return torch.from_numpy(features).float()\n","\n","    def _process_audio(self, filename, subset):\n","        \"\"\"Full processing pipeline logic, extracted for caching.\"\"\"\n","        folder_name = f\"ASVspoof2019_LA_{subset}\"\n","        file_path = os.path.join(DATASET_ROOT, folder_name, \"flac\", f\"{filename}.flac\")\n","\n","        try:\n","            audio_np, sr = sf.read(file_path, dtype='float32')\n","\n","            # 1. Temporal (VAD + Folding)\n","            audio_np = self._process_temporal_structure(audio_np, sr)\n","\n","            # 2. Standardization (Loudness)\n","            audio_linear = self._standardize_loudness(audio_np, sr)\n","\n","            # 3. Features (from linear audio)\n","            extra_features = self.extract_robust_features(audio_linear, sr)\n","\n","            # 4. Input Branch (Mu-Law)\n","            waveform = self._apply_mu_law(audio_linear, mu=255)\n","\n","            if waveform.ndim == 1:\n","                waveform = waveform.unsqueeze(0)\n","            else:\n","                waveform = waveform.t()\n","\n","        except Exception as e:\n","            # Fallback for corrupted files\n","            waveform = torch.zeros(1, self.target_length, dtype=torch.float32)\n","            extra_features = torch.zeros(3, dtype=torch.float32)\n","\n","        # Pad/Truncate (Final Check)\n","        _, w_len = waveform.shape\n","        if w_len < self.target_length:\n","            padding = self.target_length - w_len\n","            waveform = torch.nn.functional.pad(waveform, (0, padding))\n","        elif w_len > self.target_length:\n","            waveform = waveform[:, :self.target_length]\n","\n","        return waveform, extra_features\n","\n","    def __getitem__(self, idx):\n","        filename = self.filenames[idx]\n","        subset = self.subsets[idx]\n","        label = self.labels[idx]\n","\n","        # --- Cache Logic ---\n","        if self.cache:\n","            cache_path = os.path.join(self.cache_dir, f\"{filename}.pt\")\n","            if os.path.exists(cache_path):\n","                try:\n","                    # HIT: Load from disk\n","                    data = torch.load(cache_path)\n","                    return data['waveform'], label, data['features']\n","                except Exception:\n","                    # If load fails, recompute\n","                    pass\n","\n","        # MISS: Compute fresh\n","        waveform, extra_features = self._process_audio(filename, subset)\n","\n","        # Save to cache\n","        if self.cache:\n","            try:\n","                # Save as a dict to keep files organized\n","                torch.save({'waveform': waveform, 'features': extra_features}, cache_path)\n","            except Exception:\n","                pass\n","\n","        return waveform, label, extra_features"],"metadata":{"id":"Q2VYVTfZKjHu","executionInfo":{"status":"ok","timestamp":1764944519660,"user_tz":180,"elapsed":62,"user":{"displayName":"Tiago Luz","userId":"17328043178737961243"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# INGESTION"],"metadata":{"id":"nz7BN8l5VlvP"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import zipfile\n","import shutil\n","\n","def prepare_dataset_files():\n","    \"\"\"Checks for dataset existence and unzips if necessary.\"\"\"\n","    # Check if files already extracted\n","    if not os.path.exists(PATHS['train']['protocol']):\n","        print(f\"Dataset not found at {DATASET_ROOT}\")\n","\n","        if os.path.exists(ZIP_PATH):\n","            print(f\"Found zip file in Drive at: {ZIP_PATH}\")\n","\n","            # Create local raw directory\n","            os.makedirs(RAW_DIR, exist_ok=True)\n","\n","            # Extract directly from Drive to Local VM\n","            print(f\"Extracting to local VM: {RAW_DIR} ...\")\n","            # Using !unzip is often faster in Colab cells, but zipfile is portable python\n","            !unzip -q -o \"{ZIP_PATH}\" -d \"{RAW_DIR}\"\n","            # with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n","            #     zip_ref.extractall(RAW_DIR)\n","            print(\"Extraction complete.\")\n","        else:\n","            raise FileNotFoundError(f\"Zip file not found at {ZIP_PATH}. Check your Drive path.\")\n","    else:\n","        print(f\"Raw dataset files found at {DATASET_ROOT}.\")\n","\n","def parse_asvspoof_protocol(protocol_path, audio_dir, subset_name):\n","    \"\"\"Parses ASVspoof protocol text files.\"\"\"\n","    if not os.path.exists(protocol_path):\n","        print(f\"Warning: Protocol file not found: {protocol_path}\")\n","        return pd.DataFrame()\n","\n","    data = []\n","    with open(protocol_path, 'r') as f:\n","        lines = f.readlines()\n","\n","    for line in lines:\n","        parts = line.strip().split(' ')\n","        if len(parts) < 5: continue\n","        filename = parts[1]\n","        label_str = parts[4]\n","        file_path = os.path.join(audio_dir, f\"{filename}.flac\")\n","\n","        data.append({\n","            \"path\": file_path,\n","            \"filename\": filename,\n","            \"label_str\": label_str,\n","            \"label\": LABEL_MAP.get(label_str, -1),\n","            \"subset\": subset_name\n","        })\n","    return pd.DataFrame(data)\n","\n","def ingest_datasets():\n","    # Define cache paths\n","    os.makedirs(INTERMEDIARY_DIR, exist_ok=True)\n","    cache_train = os.path.join(INTERMEDIARY_DIR, \"train.csv\")\n","    cache_dev = os.path.join(INTERMEDIARY_DIR, \"dev.csv\")\n","    cache_eval = os.path.join(INTERMEDIARY_DIR, \"eval.csv\")\n","\n","    # CHECK: If cached files exist, load them and skip processing\n","    if os.path.exists(cache_train) and os.path.exists(cache_dev) and os.path.exists(cache_eval):\n","        print(f\"--- Found cached data in {INTERMEDIARY_DIR} ---\")\n","        print(\"Loading from CSVs...\")\n","        train_df = pd.read_csv(cache_train)\n","        dev_df = pd.read_csv(cache_dev)\n","        eval_df = pd.read_csv(cache_eval)\n","        print(\"Loaded successfully.\")\n","        return train_df, dev_df, eval_df\n","\n","    # PROCESS: If no cache, run full ingestion\n","    print(\"--- No cache found. Starting raw ingestion ---\")\n","\n","    # 1. Unzip if needed\n","    prepare_dataset_files()\n","\n","    # 2. Parse Protocols\n","    print(f\"Parsing Train set...\")\n","    train_df = parse_asvspoof_protocol(PATHS[\"train\"][\"protocol\"], PATHS[\"train\"][\"audio\"], \"train\")\n","\n","    print(f\"Parsing Dev set...\")\n","    dev_df = parse_asvspoof_protocol(PATHS[\"dev\"][\"protocol\"], PATHS[\"dev\"][\"audio\"], \"dev\")\n","\n","    print(f\"Parsing Eval set...\")\n","    eval_df = parse_asvspoof_protocol(PATHS[\"eval\"][\"protocol\"], PATHS[\"eval\"][\"audio\"], \"eval\")\n","\n","    # 3. Save to Intermediary Folder\n","    print(f\"--- Saving intermediary files to {INTERMEDIARY_DIR} ---\")\n","\n","    train_df.to_csv(cache_train, index=False)\n","    dev_df.to_csv(cache_dev, index=False)\n","    eval_df.to_csv(cache_eval, index=False)\n","    print(\"Saved train.csv, dev.csv, and eval.csv\")\n","\n","    return train_df, dev_df, eval_df\n","\n","if __name__ == \"__main__\":\n","    ingest_datasets()"],"metadata":{"id":"qw7Ck3CeL1OK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"107509ac-6337-4449-9b78-e9ac5ea2298a","executionInfo":{"status":"ok","timestamp":1764944120886,"user_tz":180,"elapsed":227700,"user":{"displayName":"Tiago Luz","userId":"17328043178737961243"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["--- No cache found. Starting raw ingestion ---\n","Dataset not found at /content/data/01_raw/LA\n","Found zip file in Drive at: /content/drive/MyDrive/UFSC/topicos_especiais_aplicacoes/data/DS_10283_3336/LA.zip\n","Extracting to local VM: /content/data/01_raw ...\n","Extraction complete.\n","Parsing Train set...\n","Parsing Dev set...\n","Parsing Eval set...\n","--- Saving intermediary files to /content/data/02_intermediary ---\n","Saved train.csv, dev.csv, and eval.csv\n"]}]},{"cell_type":"markdown","source":["# MODEL"],"metadata":{"id":"vPDLgfb6VzrM"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# --- One-Class Learning Loss: OC-Softmax ---\n","class OCSoftmax(nn.Module):\n","    \"\"\"\n","    One-Class Softmax Loss (from ASVspoof 2019 baseline strategies).\n","    Encourages real speech (class 0) to be compact, and spoof (class 1) to be distant.\n","    \"\"\"\n","    def __init__(self, feat_dim=2, r_real=0.9, r_fake=0.5, alpha=20.0):\n","        super(OCSoftmax, self).__init__()\n","        self.feat_dim = feat_dim\n","        self.r_real = r_real\n","        self.r_fake = r_fake\n","        self.alpha = alpha\n","\n","        # Center for the \"Real\" class in the embedding space\n","        self.center = nn.Parameter(torch.randn(1, self.feat_dim))\n","        nn.init.kaiming_uniform_(self.center, 0.25)\n","        self.softplus = nn.Softplus()\n","\n","    def forward(self, embeddings, labels):\n","        \"\"\"\n","        embeddings: (Batch, feat_dim) - Output from the bottleneck layer\n","        labels: (Batch,) - 0 for Real, 1 for Spoof\n","        \"\"\"\n","        # Normalize embeddings and center to hypersphere\n","        w = F.normalize(self.center, p=2, dim=1)\n","        x = F.normalize(embeddings, p=2, dim=1)\n","\n","        # Cosine similarity between embeddings and center\n","        scores = x.mm(w.t()).squeeze() # (Batch,)\n","\n","        # Bias the scores:\n","        # For Real (0): we want score > r_real\n","        # For Spoof (1): we want score < r_fake\n","        # We construct a margin-based loss\n","\n","        # Target scores based on label\n","        # If label=0 (Real), margin = r_real. If label=1 (Spoof), margin = r_fake\n","        margins = torch.where(labels == 0, self.r_real, self.r_fake)\n","\n","        # Logit calculation for OC-Softmax\n","        # Real: alpha * (r_real - score) -> Minimize this (make score large)\n","        # Fake: alpha * (score - r_fake) -> Minimize this (make score small)\n","\n","        # Note: Original OC-Softmax formulation varies. This is a simplified metric learning version.\n","        # Ideally, we return the Cross Entropy of the modified logits.\n","\n","        # Standard implementation creates 2-class logits from the similarity score\n","        # Class 0 Logit (Realness): -|score - center|\n","        # Class 1 Logit (Spoofness): |score - center|\n","\n","        # Let's stick to the simplest effective implementation for this timeframe:\n","        # 1-Class Objective: Minimize distance to center for Real, Maximize for Fake\n","\n","        dist = 1.0 - scores # Cosine distance (0 to 2)\n","\n","        # Hinge Loss equivalent for OCL\n","        loss_real = self.softplus(self.alpha * (dist - (1 - self.r_real))) # Penalize if dist > (1-r_real)\n","        loss_fake = self.softplus(self.alpha * ((1 - self.r_fake) - dist)) # Penalize if dist < (1-r_fake)\n","\n","        loss = torch.where(labels == 0, loss_real, loss_fake).mean()\n","\n","        return loss, scores\n","\n","# --- Model Components ---\n","\n","class SincConv_fast(nn.Module):\n","    def __init__(self, out_channels, kernel_size):\n","        super().__init__()\n","        if kernel_size % 2 == 0: kernel_size += 1\n","        self.conv = nn.Conv1d(1, out_channels, kernel_size=kernel_size, stride=1, padding=kernel_size//2, bias=False)\n","        self.bn = nn.BatchNorm1d(out_channels)\n","        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.leaky_relu(x)\n","        return x\n","\n","class SEBlock(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super().__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n","        self.fc = nn.Sequential(\n","            nn.Linear(channels, channels // reduction, bias=False),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(channels // reduction, channels, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        b, c, _ = x.size()\n","        y = self.avg_pool(x).view(b, c)\n","        y = self.fc(y).view(b, c, 1)\n","        return x * y.expand_as(x)\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm1d(out_channels)\n","        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm1d(out_channels)\n","        self.se = SEBlock(out_channels)\n","        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n","\n","        self.downsample = None\n","        if in_channels != out_channels:\n","            self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.leaky_relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out = self.se(out)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.leaky_relu(out)\n","        return out\n","\n","class RawNetOCL(nn.Module):\n","    \"\"\"\n","    RawNet modified to accept Extra Features and output Embedding for OCL.\n","    \"\"\"\n","    def __init__(self, d_args):\n","        super().__init__()\n","\n","        # Raw Audio Branch\n","        self.sinc_layer = SincConv_fast(out_channels=128, kernel_size=251)\n","        self.pool_sinc = nn.MaxPool1d(3)\n","        self.block0 = ResidualBlock(128, 128)\n","        self.pool0 = nn.MaxPool1d(3)\n","        self.block1 = ResidualBlock(128, 256)\n","        self.pool1 = nn.MaxPool1d(3)\n","        self.block2 = ResidualBlock(256, 512)\n","        self.pool2 = nn.MaxPool1d(3)\n","        self.block3 = ResidualBlock(512, 512)\n","        self.pool3 = nn.MaxPool1d(3)\n","        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n","\n","        # Feature Branch (Shimmer, ZCR, Centroid)\n","        # Simple MLP to upscale features to match embedding space\n","        self.feature_mlp = nn.Sequential(\n","            nn.Linear(3, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 128),\n","            nn.ReLU()\n","        )\n","\n","        # Fusion & Bottleneck\n","        # 256 (from RawNet fc1) + 128 (from Features) = 384\n","        self.fc1 = nn.Linear(512, 256)\n","        self.bn_fc = nn.BatchNorm1d(256)\n","        self.act_fc = nn.LeakyReLU(0.2)\n","\n","        # Final Embedding Layer (dimension 64 for OCL)\n","        self.bottleneck = nn.Linear(256 + 128, 64)\n","\n","    def forward(self, x_raw, x_feat):\n","        # 1. Raw Audio Path\n","        if x_raw.dim() == 2: x_raw = x_raw.unsqueeze(1)\n","        x = self.pool_sinc(self.sinc_layer(x_raw))\n","        x = self.pool0(self.block0(x))\n","        x = self.pool1(self.block1(x))\n","        x = self.pool2(self.block2(x))\n","        x = self.pool3(self.block3(x))\n","        x = self.avg_pool(x).flatten(1)\n","        x_raw_emb = self.act_fc(self.bn_fc(self.fc1(x))) # 256 dim\n","\n","        # 2. Handcrafted Feature Path\n","        x_feat_emb = self.feature_mlp(x_feat) # 128 dim\n","\n","        # 3. Concatenate\n","        combined = torch.cat((x_raw_emb, x_feat_emb), dim=1) # 384 dim\n","\n","        # 4. Bottleneck (Embedding for OCL)\n","        embedding = self.bottleneck(combined) # 64 dim\n","\n","        return embedding"],"metadata":{"id":"VK8MkUheKo8h","executionInfo":{"status":"ok","timestamp":1764944121214,"user_tz":180,"elapsed":305,"user":{"displayName":"Tiago Luz","userId":"17328043178737961243"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# TRAINING"],"metadata":{"id":"kTKkV9WzWB2n"}},{"cell_type":"code","source":["import os\n","import time\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n","import optuna\n","import gc\n","from tqdm import tqdm\n","\n","# from ingestion import ingest_datasets\n","# from dataset import ASVspoofDataset\n","# from model import RawNet, FocalLoss\n","\n","# Define path for saving parameters\n","BEST_PARAMS_PATH = os.path.join(MODEL_DIR, \"best_params_ocl.json\")\n","BEST_MODEL_PATH = os.path.join(MODEL_DIR, \"oc_loss_best.pth\")\n","\n","def get_balanced_loader(dataset, batch_size):\n","    targets = dataset.labels\n","    class_counts = torch.bincount(targets)\n","    class_weights = 1. / class_counts.float()\n","    sample_weights = class_weights[targets]\n","    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n","    return DataLoader(dataset, batch_size=batch_size, shuffle=False, sampler=sampler, num_workers=0, pin_memory=True)\n","\n","def train_epoch(model, loader, optimizer, criterion, device, scaler, accum_steps):\n","    model.train()\n","    running_loss = 0.0\n","\n","    pbar = tqdm(loader, desc=\"Training\", unit=\"batch\", leave=False)\n","    optimizer.zero_grad(set_to_none=True)\n","\n","    for i, (inputs, labels, extra_feats) in enumerate(pbar):\n","        inputs = inputs.to(device, non_blocking=True)\n","        extra_feats = extra_feats.to(device, non_blocking=True) # Send features to GPU\n","        labels = labels.to(device, non_blocking=True)\n","\n","        with torch.amp.autocast('cuda'):\n","            # Forward pass now takes two inputs\n","            embeddings = model(inputs, extra_feats)\n","\n","            # OCL Loss returns (loss, scores)\n","            loss, _ = criterion(embeddings, labels)\n","\n","            loss = loss / accum_steps\n","\n","        scaler.scale(loss).backward()\n","\n","        if (i + 1) % accum_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad(set_to_none=True)\n","\n","        loss_val = loss.item() * accum_steps\n","        running_loss += loss_val\n","        pbar.set_postfix(loss=f\"{loss_val:.4f}\")\n","\n","    if (i + 1) % accum_steps != 0:\n","        scaler.step(optimizer)\n","        scaler.update()\n","        optimizer.zero_grad(set_to_none=True)\n","\n","    return running_loss / len(loader)\n","\n","def validate_epoch(model, loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    pbar = tqdm(loader, desc=\"Validating\", unit=\"batch\", leave=False)\n","\n","    with torch.no_grad():\n","        for inputs, labels, extra_feats in pbar:\n","            inputs = inputs.to(device, non_blocking=True)\n","            extra_feats = extra_feats.to(device, non_blocking=True)\n","            labels = labels.to(device, non_blocking=True)\n","\n","            with torch.amp.autocast('cuda'):\n","                embeddings = model(inputs, extra_feats)\n","                loss, _ = criterion(embeddings, labels)\n","\n","            loss_val = loss.item()\n","            running_loss += loss_val\n","            pbar.set_postfix(loss=f\"{loss_val:.4f}\")\n","\n","    return running_loss / len(loader)\n","\n","def run_final_training(train_dataset, dev_dataset, params):\n","    print(\"\\n\" + \"=\"*40)\n","    print(f\"FINAL TRAINING STARTED (OCL + Features)\")\n","    print(f\"Params: {params}\")\n","    print(\"=\"*40)\n","\n","    gc.collect()\n","    if torch.cuda.is_available(): torch.cuda.empty_cache()\n","\n","    model = RawNetOCL(d_args={}).to(DEVICE)\n","    # OC-Softmax has trainble parameters (centers), add them to optimizer!\n","    criterion = OCSoftmax(feat_dim=64).to(DEVICE)\n","\n","    # Combine parameters from model AND loss function\n","    all_params = list(model.parameters()) + list(criterion.parameters())\n","    optimizer = optim.Adam(all_params, lr=params['lr'], weight_decay=params['weight_decay'])\n","\n","    scaler = torch.amp.GradScaler('cuda')\n","\n","    train_loader = get_balanced_loader(train_dataset, BATCH_SIZE)\n","    dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n","\n","    best_val_loss = float('inf')\n","    early_stop_counter = 0\n","    patience = PATIENCE\n","\n","    for epoch in range(FINAL_TRAINING_EPOCHS):\n","        start = time.time()\n","        t_loss = train_epoch(model, train_loader, optimizer, criterion, DEVICE, scaler, GRAD_ACCUM_STEPS)\n","        v_loss = validate_epoch(model, dev_loader, criterion, DEVICE)\n","        duration = time.time() - start\n","\n","        print(f\"Final Ep {epoch+1}/{FINAL_TRAINING_EPOCHS} | Train Loss: {t_loss:.4f} | Val Loss: {v_loss:.4f} | Time: {duration:.1f}s\")\n","\n","        if v_loss < best_val_loss:\n","            best_val_loss = v_loss\n","            early_stop_counter = 0\n","            torch.save(model.state_dict(), BEST_MODEL_PATH)\n","            # Also save the loss function state (it has learned centers!)\n","            torch.save(criterion.state_dict(), os.path.join(MODEL_DIR, \"oc_loss_best.pth\"))\n","            print(f\"  -> Model & Centers Saved\")\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= patience:\n","                print(\"Early stopping.\")\n","                break\n","\n","    print(\"Final training complete.\")\n","\n","def main():\n","    print(f\"Running on: {DEVICE}\")\n","    os.makedirs(MODEL_DIR, exist_ok=True)\n","\n","    try:\n","        df_train, df_dev, df_eval = ingest_datasets()\n","    except Exception as e:\n","        print(f\"Ingestion failed: {e}\")\n","        return\n","\n","    print(\"Initializing Datasets (with Feature Extraction)...\")\n","    train_dataset = ASVspoofDataset(df_train, target_length=SAMPLES_PER_TRACK)\n","    dev_dataset = ASVspoofDataset(df_dev, target_length=SAMPLES_PER_TRACK)\n","\n","    best_params = None\n","    if os.path.exists(BEST_PARAMS_PATH):\n","        print(f\"\\n--- Found existing best params ---\")\n","        with open(BEST_PARAMS_PATH, 'r') as f:\n","            best_params = json.load(f)\n","    else:\n","        print(\"\\n--- Starting Optuna Optimization ---\")\n","        def objective(trial):\n","            gc.collect()\n","            if torch.cuda.is_available(): torch.cuda.empty_cache()\n","\n","            lr = trial.suggest_float(\"lr\", 1e-4, 1e-3, log=True)\n","            weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n","\n","            model = RawNetOCL(d_args={}).to(DEVICE)\n","            criterion = OCSoftmax(feat_dim=64).to(DEVICE)\n","\n","            all_params = list(model.parameters()) + list(criterion.parameters())\n","            optimizer = optim.Adam(all_params, lr=lr, weight_decay=weight_decay)\n","            scaler = torch.amp.GradScaler('cuda')\n","\n","            train_loader = get_balanced_loader(train_dataset, BATCH_SIZE)\n","            dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n","\n","            for epoch in range(EPOCHS):\n","                t_loss = train_epoch(model, train_loader, optimizer, criterion, DEVICE, scaler, GRAD_ACCUM_STEPS)\n","                v_loss = validate_epoch(model, dev_loader, criterion, DEVICE)\n","                trial.report(v_loss, epoch)\n","                if trial.should_prune(): raise optuna.TrialPruned()\n","            return v_loss\n","\n","        study = optuna.create_study(direction=\"minimize\")\n","        study.optimize(objective, n_trials=N_TRIALS)\n","        best_params = study.best_params\n","        with open(BEST_PARAMS_PATH, 'w') as f: json.dump(best_params, f)\n","\n","    if best_params:\n","        run_final_training(train_dataset, dev_dataset, best_params)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"jdyVFAx1MG8l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764955034459,"user_tz":180,"elapsed":10510135,"user":{"displayName":"Tiago Luz","userId":"17328043178737961243"}},"outputId":"44c35daa-5604-4675-df35-ff667ba8e5d5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on: cuda\n","--- Found cached data in /content/data/02_intermediary ---\n","Loading from CSVs...\n","Loaded successfully.\n","Initializing Datasets (with Feature Extraction)...\n","Dataset Cache enabled at: /content/data/02_intermediary/processed_cache\n","Loading Silero VAD for robust silence removal...\n"]},{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\n","Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\n","[I 2025-12-05 14:22:01,242] A new study created in memory with name: no-name-5976b888-3c6b-4e85-be2d-81f559086675\n"]},{"output_type":"stream","name":"stdout","text":["Dataset Cache enabled at: /content/data/02_intermediary/processed_cache\n","Loading Silero VAD for robust silence removal...\n","\n","--- Starting Optuna Optimization ---\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-12-05 15:31:49,978] Trial 0 finished with value: 0.8296503675222786 and parameters: {'lr': 0.0004515299023889027, 'weight_decay': 0.0006908754638688816}. Best is trial 0 with value: 0.8296503675222786.\n","[I 2025-12-05 15:42:06,247] Trial 1 finished with value: 0.7134209003038122 and parameters: {'lr': 0.000254676824060447, 'weight_decay': 0.0003000728262968881}. Best is trial 1 with value: 0.7134209003038122.\n","[I 2025-12-05 15:50:49,091] Trial 2 finished with value: 0.6999015957023027 and parameters: {'lr': 0.00022221315468268574, 'weight_decay': 5.50455069986499e-05}. Best is trial 2 with value: 0.6999015957023027.\n"]},{"output_type":"stream","name":"stdout","text":["\n","========================================\n","FINAL TRAINING STARTED (OCL + Features)\n","Params: {'lr': 0.00022221315468268574, 'weight_decay': 5.50455069986499e-05}\n","========================================\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 1/50 | Train Loss: 1.8675 | Val Loss: 2.1463 | Time: 103.7s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 2/50 | Train Loss: 0.9467 | Val Loss: 1.3449 | Time: 103.4s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 3/50 | Train Loss: 0.7143 | Val Loss: 1.0867 | Time: 103.9s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 4/50 | Train Loss: 0.4092 | Val Loss: 1.5310 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 5/50 | Train Loss: 0.3049 | Val Loss: 2.3571 | Time: 103.4s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 6/50 | Train Loss: 0.2673 | Val Loss: 0.7442 | Time: 103.7s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 7/50 | Train Loss: 0.2106 | Val Loss: 0.5715 | Time: 103.4s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 8/50 | Train Loss: 0.1968 | Val Loss: 0.3561 | Time: 103.5s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 9/50 | Train Loss: 0.1427 | Val Loss: 1.1288 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 10/50 | Train Loss: 0.1481 | Val Loss: 1.0792 | Time: 103.4s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 11/50 | Train Loss: 0.1409 | Val Loss: 0.9539 | Time: 103.4s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 12/50 | Train Loss: 0.1543 | Val Loss: 0.9401 | Time: 103.7s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 13/50 | Train Loss: 0.1212 | Val Loss: 0.4731 | Time: 103.5s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 14/50 | Train Loss: 0.1419 | Val Loss: 0.8466 | Time: 103.5s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 15/50 | Train Loss: 0.0958 | Val Loss: 0.4215 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 16/50 | Train Loss: 0.1204 | Val Loss: 0.7621 | Time: 103.4s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 17/50 | Train Loss: 0.1477 | Val Loss: 0.5525 | Time: 103.3s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 18/50 | Train Loss: 0.0831 | Val Loss: 0.3489 | Time: 103.6s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 19/50 | Train Loss: 0.0958 | Val Loss: 0.3388 | Time: 103.4s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 20/50 | Train Loss: 0.1032 | Val Loss: 0.6013 | Time: 103.4s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 21/50 | Train Loss: 0.0914 | Val Loss: 0.4299 | Time: 103.8s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 22/50 | Train Loss: 0.0910 | Val Loss: 1.0005 | Time: 103.5s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 23/50 | Train Loss: 0.1164 | Val Loss: 0.4083 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 24/50 | Train Loss: 0.0932 | Val Loss: 0.4427 | Time: 103.4s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 25/50 | Train Loss: 0.0969 | Val Loss: 0.3468 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 26/50 | Train Loss: 0.1011 | Val Loss: 0.3373 | Time: 103.9s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 27/50 | Train Loss: 0.0891 | Val Loss: 0.4420 | Time: 103.8s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 28/50 | Train Loss: 0.0847 | Val Loss: 0.2781 | Time: 103.9s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 29/50 | Train Loss: 0.0962 | Val Loss: 0.1963 | Time: 103.9s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 30/50 | Train Loss: 0.0939 | Val Loss: 0.2725 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 31/50 | Train Loss: 0.0864 | Val Loss: 0.4077 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 32/50 | Train Loss: 0.0861 | Val Loss: 0.3446 | Time: 103.7s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 33/50 | Train Loss: 0.0863 | Val Loss: 0.3718 | Time: 103.4s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 34/50 | Train Loss: 0.1064 | Val Loss: 0.3335 | Time: 103.5s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 35/50 | Train Loss: 0.0876 | Val Loss: 0.8637 | Time: 103.9s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 36/50 | Train Loss: 0.0792 | Val Loss: 0.3055 | Time: 103.5s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 37/50 | Train Loss: 0.0873 | Val Loss: 0.3465 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 38/50 | Train Loss: 0.0826 | Val Loss: 0.2468 | Time: 103.8s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 39/50 | Train Loss: 0.0840 | Val Loss: 0.1910 | Time: 103.5s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 40/50 | Train Loss: 0.0774 | Val Loss: 0.2530 | Time: 103.8s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 41/50 | Train Loss: 0.0680 | Val Loss: 0.1979 | Time: 103.4s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 42/50 | Train Loss: 0.0810 | Val Loss: 0.5140 | Time: 103.5s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 43/50 | Train Loss: 0.0999 | Val Loss: 0.2179 | Time: 103.8s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 44/50 | Train Loss: 0.0790 | Val Loss: 0.3879 | Time: 103.7s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 45/50 | Train Loss: 0.0923 | Val Loss: 0.2023 | Time: 103.5s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 46/50 | Train Loss: 0.0825 | Val Loss: 0.1898 | Time: 103.6s\n","  -> Model & Centers Saved\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 47/50 | Train Loss: 0.0749 | Val Loss: 0.3722 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 48/50 | Train Loss: 0.1048 | Val Loss: 0.3428 | Time: 103.6s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 49/50 | Train Loss: 0.0797 | Val Loss: 0.2936 | Time: 103.7s\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Final Ep 50/50 | Train Loss: 0.0733 | Val Loss: 0.2666 | Time: 103.5s\n","Final training complete.\n"]}]},{"cell_type":"code","source":["import os\n","import time\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import roc_curve, confusion_matrix\n","from torch.utils.data import DataLoader, Subset\n","from tqdm import tqdm\n","\n","os.makedirs(EVALUATION_DIR, exist_ok=True)\n","\n","def compute_eer(bonafide_scores, spoof_scores):\n","    \"\"\"\n","    Computes EER given scores where:\n","    High Score = Bonafide (Similarity to Real Center)\n","    Low Score = Spoof\n","    \"\"\"\n","    # y_true: 1 for Bonafide, 0 for Spoof (Standard for similarity-based ROC)\n","    y_true = np.concatenate([np.ones(len(bonafide_scores)), np.zeros(len(spoof_scores))])\n","    y_scores = np.concatenate([bonafide_scores, spoof_scores])\n","\n","    fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n","\n","    # EER is where False Rejection Rate (1-TPR) equals False Acceptance Rate (FPR)\n","    fnr = 1 - tpr\n","    eer_threshold_idx = np.nanargmin(np.absolute((fnr - fpr)))\n","    eer = fpr[eer_threshold_idx]\n","    threshold = thresholds[eer_threshold_idx]\n","\n","    return eer, threshold\n","\n","def plot_confusion_matrix(y_true, y_pred, save_path):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=['Bonafide (0)', 'Spoof (1)'],\n","                yticklabels=['Bonafide (0)', 'Spoof (1)'])\n","    plt.title('Confusion Matrix - ASVspoof OCL Evaluation')\n","    plt.ylabel('Actual Label')\n","    plt.xlabel('Predicted Label')\n","    plt.savefig(save_path)\n","    plt.close()\n","\n","def evaluate_model():\n","    print(f\"--- Starting Evaluation on {DEVICE} (OCL + Robust Features) ---\")\n","\n","    # 1. Ensure Data Exists\n","    csv_path = os.path.join(BASE_DATA_DIR, \"02_intermediary\", \"eval.csv\")\n","    if not os.path.exists(csv_path):\n","        print(\"Eval CSV not found. Running ingestion...\")\n","        _, _, df_eval = ingest_datasets()\n","    else:\n","        df_eval = pd.read_csv(csv_path)\n","\n","    # 2. Initialize Dataset (Automatically uses VAD/R128/Mu-Law/Features)\n","    print(\"Initializing Dataset pipeline...\")\n","    full_eval_dataset = ASVspoofDataset(df_eval, target_length=SAMPLES_PER_TRACK, cache=True)\n","\n","    if EVAL_SAMPLES is not None and EVAL_SAMPLES < len(full_eval_dataset):\n","        indices = list(range(EVAL_SAMPLES))\n","        eval_dataset = Subset(full_eval_dataset, indices)\n","        print(f\"Subset selected: {len(eval_dataset)} samples.\")\n","    else:\n","        eval_dataset = full_eval_dataset\n","        print(f\"Full evaluation set: {len(eval_dataset)} samples.\")\n","\n","    # 3. DataLoader (Batching for speed)\n","    eval_loader = DataLoader(eval_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False, num_workers=0)\n","\n","    # 4. Load Model & Loss Centers\n","    model = RawNetOCL(d_args={}).to(DEVICE)\n","    loss_fn = OCSoftmax(feat_dim=64).to(DEVICE)\n","\n","    model_path = os.path.join(MODEL_DIR, \"raw_tf_net_best.pth\")\n","    loss_path = os.path.join(MODEL_DIR, \"oc_loss_best.pth\")\n","\n","    if not os.path.exists(model_path):\n","        print(f\"CRITICAL: Model weights not found at {model_path}\")\n","        return\n","\n","    print(f\"Loading weights from {model_path}...\")\n","    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n","\n","    if os.path.exists(loss_path):\n","        loss_fn.load_state_dict(torch.load(loss_path, map_location=DEVICE))\n","        print(\"Loaded OCL Centers (Crucial for scoring).\")\n","    else:\n","        print(\"WARNING: Loss centers not found. Scores will be based on random centers (Results will be garbage).\")\n","\n","    model.eval()\n","\n","    bonafide_scores = []\n","    spoof_scores = []\n","    inference_times = []\n","\n","    pbar = tqdm(eval_loader, desc=\"Evaluating\", unit=\"batch\")\n","\n","    with torch.no_grad():\n","        for inputs, labels, extra_feats in pbar:\n","            inputs = inputs.to(DEVICE)\n","            extra_feats = extra_feats.to(DEVICE)\n","\n","            # Measure Inference Time\n","            start_time = time.time()\n","            embeddings = model(inputs, extra_feats)\n","            loss, scores = loss_fn(embeddings, labels.to(DEVICE)) # Scores = Similarity to Bonafide Center\n","            end_time = time.time()\n","\n","            batch_time = (end_time - start_time) * 1000\n","            inference_times.extend([batch_time / len(inputs)] * len(inputs)) # Avg per sample\n","\n","            # Separate scores by label\n","            scores_np = scores.cpu().numpy()\n","            labels_np = labels.cpu().numpy()\n","\n","            # Label 0 = Bonafide, 1 = Spoof\n","            bonafide_scores.extend(scores_np[labels_np == 0])\n","            spoof_scores.extend(scores_np[labels_np == 1])\n","\n","    if len(bonafide_scores) == 0 or len(spoof_scores) == 0:\n","        print(\"Error: Dataset missing one of the classes (Bonafide or Spoof). Cannot compute EER.\")\n","        return\n","\n","    bonafide_scores = np.array(bonafide_scores)\n","    spoof_scores = np.array(spoof_scores)\n","\n","    # 5. Compute Metrics\n","    eer, threshold = compute_eer(bonafide_scores, spoof_scores)\n","\n","    # Confusion Matrix Logic\n","    # 0 = Bonafide, 1 = Spoof\n","    y_true_cm = np.concatenate([np.zeros(len(bonafide_scores)), np.ones(len(spoof_scores))])\n","    y_scores_cm = np.concatenate([bonafide_scores, spoof_scores])\n","\n","    # Decision: Score >= Threshold means \"Similar to Real\" -> Predict Bonafide (0)\n","    y_pred_cm = np.where(y_scores_cm >= threshold, 0, 1)\n","\n","    avg_inference_time = np.mean(inference_times)\n","\n","    # 6. Report Generation\n","    report_lines = []\n","    report_lines.append(\"\\n\" + \"=\"*40)\n","    report_lines.append(\"   ROBUST PIPELINE EVALUATION REPORT   \")\n","    report_lines.append(\"=\"*40)\n","\n","    report_lines.append(f\"Model: RawNetOCL + TEO/PCEN Features\")\n","    report_lines.append(f\"Total Samples: {len(eval_dataset)}\")\n","    report_lines.append(f\"Bonafide Samples: {len(bonafide_scores)}\")\n","    report_lines.append(f\"Spoof Samples: {len(spoof_scores)}\")\n","    report_lines.append(\"-\" * 30)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true_cm, y_pred_cm).ravel()\n","\n","    # Metrics Definitions:\n","    # False Reject (FRR): Bonafide (0) classified as Spoof (1) -> FP in this CM setup\n","    frr = fp / (tn + fp) if (tn + fp) > 0 else 0.0\n","\n","    # False Accept (FAR): Spoof (1) classified as Bonafide (0) -> FN in this CM setup\n","    far = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n","\n","    report_lines.append(f\"[Metric] Equal Error Rate (EER): {eer:.4%}\")\n","    report_lines.append(f\"[Metric] FAR (False Accept Rate): {far:.4%}\")\n","    report_lines.append(f\"[Metric] FRR (False Reject Rate): {frr:.4%}\")\n","    report_lines.append(f\"[Metric] Avg Inference Latency: {avg_inference_time:.2f} ms\")\n","    report_lines.append(f\"[Info] Optimal Threshold (Cosine Sim): {threshold:.4f}\")\n","\n","    report_lines.append(\"-\" * 30)\n","    report_lines.append(\"Performance Targets Check:\")\n","    report_lines.append(f\"[*] EER <= 5%? {'PASSED' if eer <= 0.05 else 'FAILED'}\")\n","    report_lines.append(f\"[*] FAR < 1%? {'PASSED' if far < 0.01 else 'FAILED'}\")\n","    report_lines.append(f\"[*] Latency < 100ms? {'PASSED' if avg_inference_time < 100 else 'FAILED'}\")\n","\n","    final_report = \"\\n\".join(report_lines)\n","\n","    # Output\n","    print(final_report)\n","\n","    report_path = os.path.join(EVALUATION_DIR, \"evaluation_report.txt\")\n","    with open(report_path, \"w\") as f:\n","        f.write(final_report)\n","    print(f\"\\n[Saved] Report saved to: {report_path}\")\n","\n","    cm_path = os.path.join(EVALUATION_DIR, \"confusion_matrix.png\")\n","    plot_confusion_matrix(y_true_cm, y_pred_cm, cm_path)\n","    print(f\"[Saved] Confusion Matrix saved to: {cm_path}\")\n","\n","if __name__ == \"__main__\":\n","    evaluate_model()"],"metadata":{"id":"21lzDM4_NVcg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764960144687,"user_tz":180,"elapsed":5090062,"user":{"displayName":"Tiago Luz","userId":"17328043178737961243"}},"outputId":"a4eebfc1-b854-449a-8478-9bcb25b7fd2e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Evaluation on cuda (OCL + Robust Features) ---\n","Initializing Dataset pipeline...\n","Dataset Cache enabled at: /content/data/02_intermediary/processed_cache\n","Loading Silero VAD for robust silence removal...\n"]},{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\n"]},{"output_type":"stream","name":"stdout","text":["Full evaluation set: 71237 samples.\n","Loading weights from /content/drive/MyDrive/UFSC/topicos_especiais_aplicacoes/data/04_model/raw_tf_net_best.pth...\n","Loaded OCL Centers (Crucial for scoring).\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|| 279/279 [1:24:46<00:00, 18.23s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["\n","========================================\n","   ROBUST PIPELINE EVALUATION REPORT   \n","========================================\n","Model: RawNetOCL + TEO/PCEN Features\n","Total Samples: 71237\n","Bonafide Samples: 7355\n","Spoof Samples: 63882\n","------------------------------\n","[Metric] Equal Error Rate (EER): 50.3663%\n","[Metric] FAR (False Accept Rate): 50.3663%\n","[Metric] FRR (False Reject Rate): 50.3603%\n","[Metric] Avg Inference Latency: 1.17 ms\n","[Info] Optimal Threshold (Cosine Sim): -0.0090\n","------------------------------\n","Performance Targets Check:\n","[*] EER <= 5%? FAILED\n","[*] FAR < 1%? FAILED\n","[*] Latency < 100ms? PASSED\n","\n","[Saved] Report saved to: /content/drive/MyDrive/UFSC/topicos_especiais_aplicacoes/data/05_evaluation/evaluation_report.txt\n","[Saved] Confusion Matrix saved to: /content/drive/MyDrive/UFSC/topicos_especiais_aplicacoes/data/05_evaluation/confusion_matrix.png\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Bu_26LnehOBf"},"execution_count":null,"outputs":[]}]}